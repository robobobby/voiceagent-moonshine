<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>VoiceAgent</title>
<style>
  :root {
    --bg: #0a0a0f;
    --surface: #14141f;
    --border: #2a2a3a;
    --text: #e8e8f0;
    --text-dim: #888899;
    --accent: #6366f1;
    --accent-glow: rgba(99, 102, 241, 0.3);
    --success: #22c55e;
    --error: #ef4444;
  }
  * { margin: 0; padding: 0; box-sizing: border-box; }
  body {
    font-family: 'SF Mono', 'Fira Code', 'JetBrains Mono', monospace;
    background: var(--bg);
    color: var(--text);
    min-height: 100vh;
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    padding: 2rem;
  }
  h1 {
    font-size: 1.2rem;
    font-weight: 400;
    letter-spacing: 0.2em;
    text-transform: uppercase;
    color: var(--text-dim);
    margin-bottom: 3rem;
  }
  h1 span { color: var(--accent); }

  .mic-container {
    position: relative;
    width: 160px;
    height: 160px;
    margin-bottom: 2rem;
  }
  .mic-ring {
    position: absolute;
    inset: 0;
    border-radius: 50%;
    border: 2px solid var(--border);
    transition: border-color 0.3s, box-shadow 0.3s;
  }
  .recording .mic-ring {
    border-color: var(--error);
    box-shadow: 0 0 40px rgba(239, 68, 68, 0.3);
    animation: pulse-ring 1.5s ease-in-out infinite;
  }
  @keyframes pulse-ring {
    0%, 100% { transform: scale(1); opacity: 1; }
    50% { transform: scale(1.08); opacity: 0.7; }
  }
  .mic-btn {
    position: absolute;
    inset: 12px;
    border-radius: 50%;
    background: var(--surface);
    border: none;
    cursor: pointer;
    display: flex;
    align-items: center;
    justify-content: center;
    transition: background 0.3s;
  }
  .mic-btn:hover { background: #1a1a2a; }
  .mic-btn svg { width: 48px; height: 48px; fill: var(--text-dim); transition: fill 0.3s; }
  .recording .mic-btn svg { fill: var(--error); }

  .status {
    font-size: 0.75rem;
    color: var(--text-dim);
    margin-bottom: 2rem;
    height: 1.2em;
  }
  .status.connected::before {
    content: '●';
    color: var(--success);
    margin-right: 0.5em;
  }
  .status.disconnected::before {
    content: '●';
    color: var(--error);
    margin-right: 0.5em;
  }

  .transcript-area {
    width: 100%;
    max-width: 640px;
    min-height: 200px;
    max-height: 60vh;
    overflow-y: auto;
    padding: 1.5rem;
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: 8px;
  }
  .transcript-entry {
    margin-bottom: 1rem;
    padding-bottom: 1rem;
    border-bottom: 1px solid var(--border);
  }
  .transcript-entry:last-child { border-bottom: none; margin-bottom: 0; padding-bottom: 0; }
  .transcript-entry .meta {
    font-size: 0.65rem;
    color: var(--text-dim);
    margin-bottom: 0.3rem;
  }
  .transcript-entry .text {
    font-size: 0.9rem;
    line-height: 1.5;
  }
  .transcript-entry .text.user { color: var(--accent); }

  .visualizer {
    width: 100%;
    max-width: 640px;
    height: 48px;
    margin-bottom: 1rem;
  }
  .visualizer canvas {
    width: 100%;
    height: 100%;
    border-radius: 4px;
  }

  .empty-state {
    color: var(--text-dim);
    font-size: 0.8rem;
    text-align: center;
    padding: 2rem 0;
  }
</style>
</head>
<body>
  <h1><span>Voice</span>Agent</h1>

  <div class="visualizer">
    <canvas id="visualizer"></canvas>
  </div>

  <div class="mic-container" id="micContainer">
    <div class="mic-ring"></div>
    <button class="mic-btn" id="micBtn" title="Hold to speak">
      <svg viewBox="0 0 24 24"><path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3zm-1-9c0-.55.45-1 1-1s1 .45 1 1v6c0 .55-.45 1-1 1s-1-.45-1-1V5zm6 6c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z"/></svg>
    </button>
  </div>

  <div class="status disconnected" id="status">connecting...</div>

  <div class="transcript-area" id="transcriptArea">
    <div class="empty-state">Hold the mic button and speak.<br>Release to transcribe.</div>
  </div>

<script>
const WS_URL = 'ws://localhost:8765';
const SAMPLE_RATE = 16000;

let ws = null;
let audioCtx = null;
let mediaStream = null;
let recording = false;
let audioChunks = [];
let analyser = null;
let animFrame = null;

// WebSocket
function connect() {
  ws = new WebSocket(WS_URL);
  ws.binaryType = 'arraybuffer';

  ws.onopen = () => {
    document.getElementById('status').className = 'status connected';
    document.getElementById('status').textContent = 'ready — moonshine tiny-en';
  };
  ws.onclose = () => {
    document.getElementById('status').className = 'status disconnected';
    document.getElementById('status').textContent = 'disconnected — reconnecting...';
    setTimeout(connect, 2000);
  };
  ws.onmessage = (e) => {
    const data = JSON.parse(e.data);
    if (data.type === 'transcription') {
      addTranscript(data);
    } else if (data.type === 'error') {
      addError(data.message);
    }
  };
}

function addTranscript(data) {
  const area = document.getElementById('transcriptArea');
  // Remove empty state
  const empty = area.querySelector('.empty-state');
  if (empty) empty.remove();

  const entry = document.createElement('div');
  entry.className = 'transcript-entry';
  entry.innerHTML = `
    <div class="meta">${data.audio_seconds}s audio → ${data.duration_ms}ms inference</div>
    <div class="text user">${escapeHtml(data.text)}</div>
  `;
  area.appendChild(entry);
  area.scrollTop = area.scrollHeight;
}

function addError(msg) {
  const area = document.getElementById('transcriptArea');
  const empty = area.querySelector('.empty-state');
  if (empty) empty.remove();
  const entry = document.createElement('div');
  entry.className = 'transcript-entry';
  entry.innerHTML = `<div class="text" style="color:var(--error)">${escapeHtml(msg)}</div>`;
  area.appendChild(entry);
}

function escapeHtml(s) {
  return s.replace(/&/g,'&amp;').replace(/</g,'&lt;').replace(/>/g,'&gt;');
}

// Audio capture
async function initAudio() {
  audioCtx = new AudioContext({ sampleRate: SAMPLE_RATE });
  mediaStream = await navigator.mediaDevices.getUserMedia({ audio: { sampleRate: SAMPLE_RATE, channelCount: 1, echoCancellation: true, noiseSuppression: true } });
  const source = audioCtx.createMediaStreamSource(mediaStream);

  analyser = audioCtx.createAnalyser();
  analyser.fftSize = 256;
  source.connect(analyser);

  // ScriptProcessor for raw PCM (AudioWorklet would be better but more complex)
  const processor = audioCtx.createScriptProcessor(4096, 1, 1);
  source.connect(processor);
  processor.connect(audioCtx.destination);

  processor.onaudioprocess = (e) => {
    if (recording) {
      const data = e.inputBuffer.getChannelData(0);
      audioChunks.push(new Float32Array(data));
    }
  };

  drawVisualizer();
}

function drawVisualizer() {
  const canvas = document.getElementById('visualizer');
  const ctx = canvas.getContext('2d');
  canvas.width = canvas.offsetWidth * 2;
  canvas.height = canvas.offsetHeight * 2;

  function draw() {
    animFrame = requestAnimationFrame(draw);
    if (!analyser) return;

    const bufLen = analyser.frequencyBinCount;
    const data = new Uint8Array(bufLen);
    analyser.getByteFrequencyData(data);

    ctx.fillStyle = '#14141f';
    ctx.fillRect(0, 0, canvas.width, canvas.height);

    const barW = (canvas.width / bufLen) * 2;
    let x = 0;
    for (let i = 0; i < bufLen; i++) {
      const h = (data[i] / 255) * canvas.height;
      const color = recording ? `rgba(239, 68, 68, ${0.3 + data[i]/255*0.7})` : `rgba(99, 102, 241, ${0.2 + data[i]/255*0.5})`;
      ctx.fillStyle = color;
      ctx.fillRect(x, canvas.height - h, barW - 1, h);
      x += barW;
    }
  }
  draw();
}

// Recording controls
function startRecording() {
  if (!audioCtx) return;
  audioChunks = [];
  recording = true;
  document.getElementById('micContainer').classList.add('recording');
  document.getElementById('status').textContent = 'listening...';
}

function stopRecording() {
  if (!recording) return;
  recording = false;
  document.getElementById('micContainer').classList.remove('recording');
  document.getElementById('status').textContent = 'transcribing...';

  // Merge chunks and send
  const totalLen = audioChunks.reduce((s, c) => s + c.length, 0);
  const merged = new Float32Array(totalLen);
  let offset = 0;
  for (const chunk of audioChunks) {
    merged.set(chunk, offset);
    offset += chunk.length;
  }

  if (ws && ws.readyState === WebSocket.OPEN) {
    ws.send(merged.buffer);
    document.getElementById('status').textContent = 'transcribing...';
  }

  setTimeout(() => {
    if (document.getElementById('status').textContent === 'transcribing...') {
      document.getElementById('status').textContent = 'ready — moonshine tiny-en';
    }
  }, 5000);
}

// Event listeners
const btn = document.getElementById('micBtn');
btn.addEventListener('mousedown', async (e) => {
  e.preventDefault();
  if (!audioCtx) await initAudio();
  startRecording();
});
btn.addEventListener('mouseup', stopRecording);
btn.addEventListener('mouseleave', () => { if (recording) stopRecording(); });

// Touch support
btn.addEventListener('touchstart', async (e) => {
  e.preventDefault();
  if (!audioCtx) await initAudio();
  startRecording();
});
btn.addEventListener('touchend', (e) => { e.preventDefault(); stopRecording(); });

// Keyboard: hold space
document.addEventListener('keydown', async (e) => {
  if (e.code === 'Space' && !e.repeat && !recording) {
    e.preventDefault();
    if (!audioCtx) await initAudio();
    startRecording();
  }
});
document.addEventListener('keyup', (e) => {
  if (e.code === 'Space' && recording) {
    e.preventDefault();
    stopRecording();
  }
});

connect();
</script>
</body>
</html>
